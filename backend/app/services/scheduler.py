"""
å®šæ—¶ä»»åŠ¡è°ƒåº¦å™¨
ç”¨äºæ‰§è¡Œå®šæ—¶æ•°æ®åŒæ­¥å’Œåˆ†æä»»åŠ¡
"""
import logging
from datetime import datetime, date, timedelta, timezone

from apscheduler.schedulers.background import BackgroundScheduler
from apscheduler.triggers.cron import CronTrigger
from sqlalchemy import func
from sqlalchemy.orm import Session

from app.database import SessionLocal
from app.services.platform_data_sync import PlatformDataSyncService

from app.services.api_analysis_service import ApiAnalysisService
from app.models.affiliate_account import AffiliateAccount
from app.models.google_ads_api_data import GoogleAdsApiData, GoogleMccAccount


logger = logging.getLogger(__name__)

# åŒ—äº¬æ—¶é—´ï¼ˆUTC+8ï¼‰
BEIJING_TZ = timezone(timedelta(hours=8))

# ä½¿ç”¨åŒ—äº¬æ—¶é—´ä½œä¸ºè°ƒåº¦å™¨çš„é»˜è®¤æ—¶åŒº
scheduler = BackgroundScheduler(timezone=BEIJING_TZ)

# ARCH-2: å…¨å±€äº’æ–¥é”ï¼Œé˜²æ­¢å®šæ—¶ä»»åŠ¡å’Œæ‰‹åŠ¨è§¦å‘åŒæ—¶æ“ä½œæ•°æ®åº“
import threading
_sync_lock = threading.Lock()


def sync_platform_data_job():
    """åŒæ­¥å¹³å°æ•°æ®ä»»åŠ¡ï¼ˆæ¯å¤©åŒ—äº¬æ—¶é—´4ç‚¹æ‰§è¡Œï¼Œé€å¤©åŒæ­¥è¿‡å»5å¤©æ•°æ®ï¼šMIDã€å•†å®¶ã€è®¢å•æ•°ã€ä½£é‡‘ã€æ‹’ä»˜ä½£é‡‘ï¼‰
    
    æ³¨æ„ï¼š
    - æ€»ä½£é‡‘ï¼šåŒ…å«æ‰€æœ‰çŠ¶æ€çš„ä½£é‡‘ï¼ˆapproved + pending + rejectedï¼‰
    - æ‹’ä»˜ä½£é‡‘ï¼šåªåŒ…å«rejectedçŠ¶æ€çš„ä½£é‡‘
    - å·²ä»˜ä½£é‡‘ï¼šåªåŒ…å«approvedçŠ¶æ€çš„ä½£é‡‘ï¼ˆæ¯å‘¨ä¸€åŒæ­¥90å¤©ï¼‰
    """
    db: Session = SessionLocal()
    try:
        logger.info("=" * 60)
        logger.info("å¼€å§‹æ‰§è¡Œå¹³å°æ•°æ®åŒæ­¥ä»»åŠ¡ï¼ˆè¿‡å»5å¤©ï¼Œé€å¤©åŒæ­¥ï¼‰...")
        
        sync_service = PlatformDataSyncService(db)
        
        # è·å–æ‰€æœ‰æ´»è·ƒçš„è”ç›Ÿè´¦å·
        active_accounts = db.query(AffiliateAccount).filter(
            AffiliateAccount.is_active == True
        ).all()
        
        logger.info(f"æ‰¾åˆ° {len(active_accounts)} ä¸ªæ´»è·ƒè´¦å·")
        
        # åŒæ­¥æœ€è¿‘5å¤©çš„æ•°æ®ï¼ˆç¡®ä¿è¦†ç›–å¯èƒ½å˜åŒ–çš„ä½£é‡‘ï¼‰
        end_date = date.today() - timedelta(days=1)  # æ˜¨å¤©
        begin_date = end_date - timedelta(days=4)  # 5å¤©å‰
        
        logger.info(f"æ—¶é—´èŒƒå›´: {begin_date.isoformat()} è‡³ {end_date.isoformat()} (å…±5å¤©)")
        
        total_success_count = 0
        total_fail_count = 0
        total_saved = 0
        
        # é€å¤©åŒæ­¥ï¼Œç¡®ä¿æ•°æ®å®Œæ•´
        current_date = begin_date
        while current_date <= end_date:
            logger.info("-" * 60)
            logger.info(f"æ­£åœ¨åŒæ­¥æ—¥æœŸ: {current_date.isoformat()}")
            
            day_success_count = 0
            day_fail_count = 0
            day_saved = 0
            
            # ä¸ºæ¯ä¸€å¤©åŒæ­¥æ‰€æœ‰è´¦å·
            for account in active_accounts:
                try:
                    logger.info(f"  åŒæ­¥è´¦å·: {account.account_name} (å¹³å°: {account.platform.platform_name if account.platform else 'æœªçŸ¥'})")
                    # é€å¤©åŒæ­¥ï¼Œæ¯æ¬¡åªåŒæ­¥ä¸€å¤©çš„æ•°æ®
                    result = sync_service.sync_account_data(
                        account.id,
                        current_date.isoformat(),
                        current_date.isoformat()  # å¼€å§‹å’Œç»“æŸæ—¥æœŸç›¸åŒï¼ŒåªåŒæ­¥ä¸€å¤©
                    )
                    
                    if result.get("success"):
                        day_success_count += 1
                        saved_count = result.get("saved_count", 0)
                        day_saved += saved_count
                        logger.info(f"  âœ“ è´¦å· {account.account_name} åŒæ­¥æˆåŠŸ: ä¿å­˜ {saved_count} æ¡è®°å½•")
                    else:
                        day_fail_count += 1
                        error_msg = result.get('message', 'æœªçŸ¥é”™è¯¯')
                        logger.error(f"  âœ— è´¦å· {account.account_name} åŒæ­¥å¤±è´¥: {error_msg}")
                except Exception as e:
                    day_fail_count += 1
                    logger.error(f"  âœ— è´¦å· {account.account_name} åŒæ­¥å¼‚å¸¸: {e}", exc_info=True)
            
            logger.info(f"æ—¥æœŸ {current_date.isoformat()} åŒæ­¥å®Œæˆ: æˆåŠŸ {day_success_count} ä¸ªè´¦å·, å¤±è´¥ {day_fail_count} ä¸ªè´¦å·, ä¿å­˜ {day_saved} æ¡è®°å½•")
            
            total_success_count += day_success_count
            total_fail_count += day_fail_count
            total_saved += day_saved
            
            # ç§»åŠ¨åˆ°ä¸‹ä¸€å¤©
            current_date += timedelta(days=1)
        
        logger.info("=" * 60)
        logger.info(f"å¹³å°æ•°æ®åŒæ­¥ä»»åŠ¡å®Œæˆï¼ˆé€å¤©åŒæ­¥ï¼‰:")
        logger.info(f"  - åŒæ­¥æ—¥æœŸæ•°: 5 å¤©")
        logger.info(f"  - æ€»æˆåŠŸæ¬¡æ•°: {total_success_count} æ¬¡")
        logger.info(f"  - æ€»å¤±è´¥æ¬¡æ•°: {total_fail_count} æ¬¡")
        logger.info(f"  - å…±ä¿å­˜: {total_saved} æ¡è®°å½•")
        logger.info(f"  - æå–å­—æ®µ: MIDã€å•†å®¶ã€è®¢å•æ•°ã€ä½£é‡‘ï¼ˆæ‰€æœ‰çŠ¶æ€ï¼‰ã€æ‹’ä»˜ä½£é‡‘ï¼ˆrejectedçŠ¶æ€ï¼‰")
        logger.info("=" * 60)
        
    except Exception as e:
        logger.error(f"å¹³å°æ•°æ®åŒæ­¥ä»»åŠ¡æ‰§è¡Œå¤±è´¥: {e}", exc_info=True)
    finally:
        db.close()


def sync_google_ads_data_job():
    """
    åŒæ­¥Google Adsæ•°æ®ä»»åŠ¡ï¼ˆæ¯å¤©åŒ—äº¬æ—¶é—´å‡Œæ™¨4ç‚¹æ‰§è¡Œï¼‰
    
    ä½¿ç”¨æœåŠ¡è´¦å·æ¨¡å¼åŒæ­¥æ‰€æœ‰æ´»è·ƒMCCçš„å¹¿å‘Šæ•°æ®
    ä»…åŒæ­¥æ˜¨å¤©çš„æ•°æ®ï¼Œç¡®ä¿æ•°æ®ç²¾å‡†ä¸”èŠ‚çœAPIé…é¢
    """
    db: Session = SessionLocal()
    try:
        logger.info("=" * 60)
        logger.info("å¼€å§‹æ‰§è¡ŒGoogle Adsæ•°æ®åŒæ­¥ä»»åŠ¡ï¼ˆæœåŠ¡è´¦å·æ¨¡å¼ï¼‰...")
        
        from app.services.google_ads_service_account_sync import GoogleAdsServiceAccountSync
        
        sync_service = GoogleAdsServiceAccountSync(db)
        
        # ä»…åŒæ­¥æ˜¨å¤©çš„æ•°æ®
        target_date = date.today() - timedelta(days=1)
        force_refresh = True  # å¼ºåˆ¶åˆ·æ–°ç¡®ä¿æ•°æ®ç²¾å‡†
        
        logger.info(f"åŒæ­¥æ—¥æœŸ: {target_date.isoformat()} (ä»…æ˜¨å¤©)")
        
        # æ‰¹é‡åŒæ­¥æ‰€æœ‰æ´»è·ƒMCC
        result = sync_service.sync_all_mccs(
            target_date=target_date,
            only_enabled=False,  # åŒæ­¥æ‰€æœ‰çŠ¶æ€çš„å¹¿å‘Šç³»åˆ—ï¼ˆåŒ…æ‹¬å·²æš‚åœï¼‰
            force_refresh=force_refresh
        )
        
        total_saved = 0
        total_mccs = 0
        
        if result.get("success"):
            total_saved = result.get('total_saved', 0)
            total_mccs = result.get('total_mccs', 0)
            logger.info(f"  âœ“ {target_date}: ä¿å­˜ {total_saved} æ¡")
            
            if result.get("quota_exhausted"):
                logger.warning("âš ï¸ é‡åˆ°APIé…é¢é™åˆ¶")
        else:
            logger.error(f"  âœ— {target_date}: {result.get('message')}")
        
        logger.info(f"âœ“ Google Adsæ•°æ®åŒæ­¥å®Œæˆ:")
        logger.info(f"  - MCCæ€»æ•°: {total_mccs}")
        logger.info(f"  - åŒæ­¥æ—¥æœŸ: ä»…æ˜¨å¤© ({target_date.isoformat()})")
        logger.info(f"  - æ€»ä¿å­˜è®°å½•: {total_saved} æ¡")
        logger.info("=" * 60)
        
    except Exception as e:
        logger.error(f"âœ— Google Adsæ•°æ®åŒæ­¥ä»»åŠ¡å¼‚å¸¸: {e}", exc_info=True)
    finally:
        db.close()


def daily_auto_sync_and_analysis_job():
    """
    æ¯å¤©æ—©ä¸Š4:00è‡ªåŠ¨æ‰§è¡Œçš„ç»Ÿä¸€ä»»åŠ¡ï¼š
    1. æ‹‰å–Google Adsæ•°æ®ï¼ˆä»…æ˜¨å¤©ï¼‰
    2. æ‹‰å–å¹¿å‘Šå¹³å°æ•°æ®ï¼ˆè¿‡å»5å¤©ï¼‰
    3. å‘¨ä¸€é¢å¤–ï¼šåŒæ­¥è¿‡å»90å¤©å¹³å°æ•°æ®ï¼ˆå«å·²ä»˜/æ‹’ä»˜ä½£é‡‘ï¼‰
    4. ç”Ÿæˆæ¯æ—¥åˆ†æ
    5. ç”ŸæˆL7Dåˆ†æï¼ˆæ¯å¤©æ‰§è¡Œï¼‰
    """
    if not _sync_lock.acquire(blocking=False):
        logger.warning("ã€æ¯æ—¥è‡ªåŠ¨ä»»åŠ¡è·³è¿‡ã€‘ä¸Šä¸€è½®å°šæœªå®Œæˆ")
        return
    try:
        _daily_auto_sync_and_analysis_inner()
    finally:
        _sync_lock.release()


def _daily_auto_sync_and_analysis_inner():
    logger.info("=" * 60)
    logger.info("ã€æ¯æ—¥è‡ªåŠ¨ä»»åŠ¡å¼€å§‹ã€‘")
    logger.info(f"å½“å‰æ—¶é—´: {datetime.now(BEIJING_TZ).strftime('%Y-%m-%d %H:%M:%S')} (åŒ—äº¬æ—¶é—´)")
    
    today = date.today()
    weekday = today.weekday()  # 0=å‘¨ä¸€, 1=å‘¨äºŒ, ..., 6=å‘¨æ—¥
    is_monday = (weekday == 0)
    
    logger.info(f"ä»Šå¤©æ˜¯: æ˜ŸæœŸ{['ä¸€','äºŒ','ä¸‰','å››','äº”','å…­','æ—¥'][weekday]}")
    if is_monday:
        logger.info("ğŸ“… å‘¨ä¸€ï¼šå°†é¢å¤–åŒæ­¥è¿‡å»90å¤©å¹³å°ä½£é‡‘æ•°æ®")
    logger.info("=" * 60)
    
    # æ­¥éª¤1: åŒæ­¥Google Adsæ•°æ®ï¼ˆä»…æ˜¨å¤©ï¼‰
    logger.info("\nã€æ­¥éª¤1/5ã€‘åŒæ­¥Google Adsæ•°æ®ï¼ˆä»…æ˜¨å¤©ï¼‰...")
    try:
        sync_google_ads_data_job()
        logger.info("âœ“ Google Adsæ•°æ®åŒæ­¥å®Œæˆ")
    except Exception as e:
        logger.error(f"âœ— Google Adsæ•°æ®åŒæ­¥å¤±è´¥: {e}")
    
    # æ­¥éª¤2: åŒæ­¥å¹³å°æ•°æ®ï¼ˆè¿‡å»5å¤©ï¼‰
    logger.info("\nã€æ­¥éª¤2/5ã€‘åŒæ­¥å¹¿å‘Šå¹³å°æ•°æ®ï¼ˆè¿‡å»5å¤©ï¼‰...")
    try:
        sync_platform_data_job()
        logger.info("âœ“ å¹¿å‘Šå¹³å°æ•°æ®åŒæ­¥å®Œæˆ")
    except Exception as e:
        logger.error(f"âœ— å¹¿å‘Šå¹³å°æ•°æ®åŒæ­¥å¤±è´¥: {e}")
    
    # æ­¥éª¤3: å‘¨ä¸€é¢å¤–åŒæ­¥è¿‡å»90å¤©å¹³å°æ•°æ®
    if is_monday:
        logger.info("\nã€æ­¥éª¤3/5ã€‘å‘¨ä¸€é¢å¤–ï¼šåŒæ­¥è¿‡å»90å¤©å¹³å°ä½£é‡‘æ•°æ®...")
        try:
            sync_platform_data_90days_job()
            logger.info("âœ“ 90å¤©å¹³å°ä½£é‡‘æ•°æ®åŒæ­¥å®Œæˆ")
        except Exception as e:
            logger.error(f"âœ— 90å¤©å¹³å°ä½£é‡‘æ•°æ®åŒæ­¥å¤±è´¥: {e}")
    else:
        logger.info("\nã€æ­¥éª¤3/5ã€‘è·³è¿‡ï¼ˆä»…å‘¨ä¸€æ‰§è¡Œ90å¤©åŒæ­¥ï¼‰")
    
    # æ­¥éª¤4: ç”Ÿæˆæ¯æ—¥åˆ†æ
    logger.info("\nã€æ­¥éª¤4/5ã€‘ç”Ÿæˆæ¯æ—¥åˆ†æ...")
    try:
        daily_analysis_job()
        logger.info("âœ“ æ¯æ—¥åˆ†æç”Ÿæˆå®Œæˆ")
    except Exception as e:
        logger.error(f"âœ— æ¯æ—¥åˆ†æç”Ÿæˆå¤±è´¥: {e}")
    
    # æ­¥éª¤5: ç”ŸæˆL7Dåˆ†æï¼ˆæ¯å¤©æ‰§è¡Œï¼‰
    logger.info("\nã€æ­¥éª¤5/5ã€‘ç”ŸæˆL7Dåˆ†æ...")
    try:
        weekly_l7d_analysis_job()
        logger.info("âœ“ L7Dåˆ†æç”Ÿæˆå®Œæˆ")
    except Exception as e:
        logger.error(f"âœ— L7Dåˆ†æç”Ÿæˆå¤±è´¥: {e}")
    
    logger.info("\n" + "=" * 60)
    logger.info("ã€æ¯æ—¥è‡ªåŠ¨ä»»åŠ¡å®Œæˆã€‘")
    logger.info("=" * 60)


def sync_google_ads_historical_job():
    """
    åŒæ­¥Google Adså†å²æ•°æ®ä»»åŠ¡ï¼ˆæ‰‹åŠ¨è§¦å‘æˆ–é¦–æ¬¡éƒ¨ç½²æ—¶æ‰§è¡Œï¼‰
    
    åŒæ­¥ä»2026å¹´1æœˆ1æ—¥è‡³æ˜¨å¤©çš„æ‰€æœ‰æ•°æ®
    """
    db: Session = SessionLocal()
    try:
        logger.info("=" * 60)
        logger.info("å¼€å§‹æ‰§è¡ŒGoogle Adså†å²æ•°æ®åŒæ­¥ä»»åŠ¡...")
        
        from app.services.google_ads_service_account_sync import GoogleAdsServiceAccountSync
        
        sync_service = GoogleAdsServiceAccountSync(db)
        
        # å†å²æ•°æ®èŒƒå›´ï¼š2026å¹´1æœˆ1æ—¥è‡³æ˜¨å¤©
        begin_date = date(2026, 1, 1)
        end_date = date.today() - timedelta(days=1)
        
        logger.info(f"åŒæ­¥æ—¥æœŸèŒƒå›´: {begin_date.isoformat()} ~ {end_date.isoformat()}")
        
        # è·å–æ‰€æœ‰æ´»è·ƒMCC
        active_mccs = db.query(GoogleMccAccount).filter(
            GoogleMccAccount.is_active == True
        ).all()
        
        logger.info(f"å¾…åŒæ­¥MCCæ•°é‡: {len(active_mccs)}")
        
        total_saved = 0
        
        for mcc in active_mccs:
            logger.info(f"åŒæ­¥MCC: {mcc.mcc_name} ({mcc.mcc_id})")
            
            result = sync_service.sync_historical_data(
                mcc.id,
                begin_date,
                end_date,
                force_refresh=False
            )
            
            if result.get("success"):
                saved = result.get("total_saved", 0)
                total_saved += saved
                logger.info(f"  âœ“ å®Œæˆ: æˆåŠŸ{result.get('success_days')}å¤©, "
                           f"å¤±è´¥{result.get('fail_days')}å¤©, ä¿å­˜{saved}æ¡")
            else:
                logger.error(f"  âœ— å¤±è´¥: {result.get('message')}")
            
            if result.get("quota_exhausted"):
                logger.warning("âš ï¸ é‡åˆ°é…é¢é™åˆ¶ï¼Œåœæ­¢åŒæ­¥")
                break
        
        logger.info(f"å†å²æ•°æ®åŒæ­¥å®Œæˆï¼Œå…±ä¿å­˜ {total_saved} æ¡è®°å½•")
        logger.info("=" * 60)
        
    except Exception as e:
        logger.error(f"âœ— Google Adså†å²æ•°æ®åŒæ­¥ä»»åŠ¡å¼‚å¸¸: {e}", exc_info=True)
    finally:
        db.close()


def check_mcc_missing_dates(db: Session, mcc_id: int, begin_date: date, end_date: date) -> list:
    """
    æ£€æŸ¥æŒ‡å®šMCCåœ¨æ—¥æœŸèŒƒå›´å†…ç¼ºå¤±æ•°æ®çš„æ—¥æœŸ
    
    Args:
        db: æ•°æ®åº“ä¼šè¯
        mcc_id: MCCçš„æ•°æ®åº“ID
        begin_date: å¼€å§‹æ—¥æœŸ
        end_date: ç»“æŸæ—¥æœŸ
    
    Returns:
        ç¼ºå¤±æ•°æ®çš„æ—¥æœŸåˆ—è¡¨
    """
    # æŸ¥è¯¢è¯¥MCCå·²æœ‰æ•°æ®çš„æ—¥æœŸï¼ˆå»é‡ï¼‰
    existing_dates_rows = db.query(
        func.distinct(GoogleAdsApiData.date)
    ).filter(
        GoogleAdsApiData.mcc_id == mcc_id,
        GoogleAdsApiData.date >= begin_date,
        GoogleAdsApiData.date <= end_date
    ).all()
    
    existing_set = {row[0] for row in existing_dates_rows}
    
    # ç”Ÿæˆå®Œæ•´æ—¥æœŸèŒƒå›´
    all_dates = []
    current = begin_date
    while current <= end_date:
        all_dates.append(current)
        current += timedelta(days=1)
    
    # æ‰¾å‡ºç¼ºå¤±æ—¥æœŸ
    missing = [d for d in all_dates if d not in existing_set]
    return missing


def backfill_missing_data_job():
    """
    æ¯å¤© 05:00 è‡ªåŠ¨è¡¥é½å†å²ç¼ºå£ï¼ˆé…é¢æ„ŸçŸ¥ï¼‰

    ä» 2026-02-01 å¼€å§‹ï¼Œæ£€æŸ¥æ‰€æœ‰ MCC çš„ç¼ºå¤±æ—¥æœŸï¼Œ
    æ¯æ¬¡æœ€å¤šè¡¥ MAX_BACKFILL_DAYS å¤© x MAX_BACKFILL_MCCS ä¸ª MCCï¼Œ
    CNY ä¼˜å…ˆï¼Œé‡åˆ°é…é¢è€—å°½ç«‹å³åœæ­¢ã€‚
    å…¨éƒ¨è¡¥é½åå‡½æ•°ç›´æ¥ returnï¼ˆé›¶å¼€é”€ï¼‰ã€‚
    """
    MAX_BACKFILL_MCCS = 2
    MAX_BACKFILL_DAYS = 5
    BACKFILL_BEGIN = date(2026, 2, 1)

    db: Session = SessionLocal()
    try:
        logger.info("=" * 60)
        logger.info("ã€å†å²æ•°æ®è‡ªåŠ¨è¡¥é½å¼€å§‹ã€‘")
        logger.info(f"å½“å‰æ—¶é—´: {datetime.now(BEIJING_TZ).strftime('%Y-%m-%d %H:%M:%S')} (åŒ—äº¬æ—¶é—´)")

        from app.services.google_ads_service_account_sync import GoogleAdsServiceAccountSync
        sync_service = GoogleAdsServiceAccountSync(db)

        end_date = date.today() - timedelta(days=1)

        all_mccs = db.query(GoogleMccAccount).filter(
            GoogleMccAccount.is_active == True
        ).all()

        # ä¸ºæ¯ä¸ª MCC è®¡ç®—ç¼ºå¤±å¤©æ•°ï¼ŒæŒ‰ï¼ˆCNYä¼˜å…ˆ, ç¼ºå£å¤§å°é™åºï¼‰æ’åº
        mcc_gaps = []
        for mcc in all_mccs:
            missing = check_mcc_missing_dates(db, mcc.id, BACKFILL_BEGIN, end_date)
            if missing:
                is_cny = 1 if mcc.currency == 'CNY' else 0
                mcc_gaps.append((mcc, missing, is_cny))

        if not mcc_gaps:
            logger.info("æ‰€æœ‰ MCC æ•°æ®å·²å®Œæ•´ï¼Œæ— éœ€è¡¥é½")
            logger.info("=" * 60)
            return

        mcc_gaps.sort(key=lambda x: (-x[2], -len(x[1])))

        total_missing = sum(len(g[1]) for g in mcc_gaps)
        logger.info(f"å…± {len(mcc_gaps)} ä¸ª MCC æœ‰æ•°æ®ç¼ºå£ï¼Œæ€»ç¼ºå¤± {total_missing} å¤©")
        logger.info(f"æœ¬æ¬¡æœ€å¤šè¡¥é½: {MAX_BACKFILL_MCCS} ä¸ª MCC x {MAX_BACKFILL_DAYS} å¤©")
        logger.info("=" * 60)

        total_saved = 0
        total_synced = 0
        mccs_processed = 0
        quota_exhausted = False

        for mcc, missing_dates, is_cny in mcc_gaps:
            if mccs_processed >= MAX_BACKFILL_MCCS or quota_exhausted:
                break

            currency_tag = "CNY" if is_cny else "USD"
            dates_this_round = missing_dates[:MAX_BACKFILL_DAYS]

            logger.info(f"\nMCC {mcc.mcc_id} ({mcc.mcc_name}) [{currency_tag}]")
            logger.info(f"  ç¼ºå¤± {len(missing_dates)} å¤©ï¼Œæœ¬æ¬¡è¡¥ {len(dates_this_round)} å¤©")

            for target_date in dates_this_round:
                try:
                    result = sync_service.sync_mcc_data(
                        mcc.id, target_date, force_refresh=False
                    )
                    if result.get("success"):
                        saved = result.get("saved_count", 0)
                        total_saved += saved
                        total_synced += 1
                        logger.info(f"  {target_date}: {saved} æ¡")
                    else:
                        logger.warning(f"  {target_date}: {result.get('message', '')[:80]}")

                    if result.get("quota_exhausted"):
                        logger.warning("é…é¢è€—å°½ï¼Œåœæ­¢è¡¥é½")
                        quota_exhausted = True
                        break
                except Exception as e:
                    logger.error(f"  {target_date} å¼‚å¸¸: {e}")

            mccs_processed += 1

        remaining = total_missing - total_synced
        logger.info("\n" + "=" * 60)
        logger.info("ã€å†å²æ•°æ®è‡ªåŠ¨è¡¥é½å®Œæˆã€‘")
        logger.info(f"  æœ¬æ¬¡è¡¥é½: {total_synced} å¤©, {total_saved} æ¡")
        logger.info(f"  å‰©ä½™ç¼ºå£: {remaining} å¤©")
        if remaining > 0:
            logger.info(f"  å°†åœ¨æ˜å¤© 05:00 ç»§ç»­è¡¥é½")
        if quota_exhausted:
            logger.warning("  æ³¨æ„: é‡åˆ°é…é¢é™åˆ¶ï¼Œæå‰ç»ˆæ­¢")
        logger.info("=" * 60)

    except Exception as e:
        logger.error(f"å†å²æ•°æ®è‡ªåŠ¨è¡¥é½ä»»åŠ¡å¼‚å¸¸: {e}", exc_info=True)
    finally:
        db.close()


def daily_analysis_job():
    """æ¯æ—¥åˆ†æä»»åŠ¡ï¼ˆæ¯å¤©åŒ—äº¬æ—¶é—´æ—©ä¸Š8ç‚¹05åˆ†æ‰§è¡Œï¼Œå–å‰ä¸€å¤©çš„å¹³å°æ•°æ®å’Œå¯¹åº”å•†å®¶çš„Google adsæ•°æ®è¿›è¡Œæ¯æ—¥åˆ†æï¼‰"""
    db: Session = SessionLocal()
    try:
        logger.info("=" * 60)
        logger.info("å¼€å§‹æ‰§è¡Œæ¯æ—¥åˆ†æä»»åŠ¡...")
        
        # åˆ†ææ˜¨å¤©çš„æ•°æ®
        target_date = date.today() - timedelta(days=1)
        logger.info(f"åˆ†ææ—¥æœŸ: {target_date.isoformat()}")
        logger.info("æ•°æ®æ¥æº: å‰ä¸€å¤©çš„å¹³å°æ•°æ® + å¯¹åº”å•†å®¶çš„Google Adsæ•°æ®")
        
        # è°ƒç”¨APIåˆ†ææœåŠ¡
        api_analysis_service = ApiAnalysisService(db)
        
        # ä¸ºæ‰€æœ‰ç”¨æˆ·ç”Ÿæˆæ¯æ—¥åˆ†æï¼ˆuser_id=Noneè¡¨ç¤ºæ‰€æœ‰ç”¨æˆ·ï¼‰
        result = api_analysis_service.generate_daily_analysis(target_date, user_id=None)
        
        if result.get("success"):
            total_records = result.get("total_records", 0)
            logger.info(f"âœ“ æ¯æ—¥åˆ†æä»»åŠ¡å®Œæˆ: {target_date.isoformat()}, å…±ç”Ÿæˆ {total_records} æ¡è®°å½•")
        else:
            logger.error(f"âœ— æ¯æ—¥åˆ†æä»»åŠ¡å¤±è´¥: {result.get('message')}")
        
        logger.info("=" * 60)
        
    except Exception as e:
        logger.error(f"âœ— æ¯æ—¥åˆ†æä»»åŠ¡æ‰§è¡Œå¤±è´¥: {e}", exc_info=True)
    finally:
        db.close()


def weekly_l7d_analysis_job():
    """æ¯å‘¨L7Dåˆ†æä»»åŠ¡ï¼ˆæ¯å‘¨ä¸€/ä¸‰/äº”åŒ—äº¬æ—¶é—´æ—©ä¸Š8ç‚¹10åˆ†è‡ªåŠ¨ç”ŸæˆL7Dæ•°æ®ï¼‰"""
    db: Session = SessionLocal()
    try:
        logger.info("=" * 60)
        logger.info("å¼€å§‹æ‰§è¡Œæ¯å‘¨L7Dåˆ†æä»»åŠ¡...")

        # ç»“æŸæ—¥æœŸä¸ºæ˜¨å¤©ï¼ˆä¸åŒ…å«ä»Šå¤©ï¼‰
        end_date = date.today() - timedelta(days=1)
        begin_date = end_date - timedelta(days=6)
        
        logger.info(f"åˆ†ææ—¥æœŸèŒƒå›´: {begin_date.isoformat()} è‡³ {end_date.isoformat()} (è¿‡å»7å¤©)")

        api_analysis_service = ApiAnalysisService(db)

        # ä¸ºæ‰€æœ‰ç”¨æˆ·ç”ŸæˆL7Dåˆ†æï¼ˆuser_id=Noneè¡¨ç¤ºæ‰€æœ‰ç”¨æˆ·ï¼‰
        result = api_analysis_service.generate_l7d_analysis(end_date, user_id=None)

        if result.get("success"):
            logger.info(
                "âœ“ æ¯å‘¨L7Dåˆ†æä»»åŠ¡å®Œæˆ: %s è‡³ %s, å…±ç”Ÿæˆ %s æ¡è®°å½•",
                result.get("begin_date"),
                result.get("end_date"),
                result.get("total_records", 0),
            )
        else:
            logger.error(f"âœ— æ¯å‘¨L7Dåˆ†æä»»åŠ¡å¤±è´¥: {result.get('message')}")

        logger.info("=" * 60)

    except Exception as e:
        logger.error("âœ— æ¯å‘¨L7Dåˆ†æä»»åŠ¡æ‰§è¡Œå¤±è´¥: %s", e, exc_info=True)
    finally:
        db.close()


def sync_platform_data_90days_job():
    """å‘¨ä¸€åŒæ­¥è¿‡å»90å¤©å¹³å°ä½£é‡‘ä»»åŠ¡ï¼ˆåŒ…å«å·²ä»˜ä½£é‡‘å’Œæ‹’ä»˜ä½£é‡‘ï¼‰
    
    æ¯å‘¨ä¸€æ—©ä¸Š4ç‚¹æ‰§è¡Œï¼ŒåŒæ­¥è¿‡å»90å¤©çš„æ‰€æœ‰ä½£é‡‘æ•°æ®ï¼Œ
    ç¡®ä¿é•¿å‘¨æœŸå†…çš„ä½£é‡‘çŠ¶æ€å˜åŒ–ï¼ˆå¦‚ä»pendingå˜ä¸ºapproved/rejectedï¼‰è¢«æ­£ç¡®æ›´æ–°
    """
    db: Session = SessionLocal()
    try:
        logger.info("=" * 60)
        logger.info("å¼€å§‹æ‰§è¡Œ90å¤©å¹³å°ä½£é‡‘åŒæ­¥ä»»åŠ¡ï¼ˆå‘¨ä¸€ä¸“ç”¨ï¼‰...")
        
        sync_service = PlatformDataSyncService(db)
        
        # è·å–æ‰€æœ‰æ´»è·ƒçš„è”ç›Ÿè´¦å·
        active_accounts = db.query(AffiliateAccount).filter(
            AffiliateAccount.is_active == True
        ).all()
        
        logger.info(f"æ‰¾åˆ° {len(active_accounts)} ä¸ªæ´»è·ƒè´¦å·")
        
        # åŒæ­¥è¿‡å»90å¤©çš„æ•°æ®
        end_date = date.today() - timedelta(days=1)  # æ˜¨å¤©
        begin_date = end_date - timedelta(days=89)  # 90å¤©å‰
        
        logger.info(f"æ—¶é—´èŒƒå›´: {begin_date.isoformat()} è‡³ {end_date.isoformat()} (å…±90å¤©)")
        logger.info("åŒæ­¥æ‰€æœ‰çŠ¶æ€çš„ä½£é‡‘ï¼ˆå«å·²ä»˜ä½£é‡‘å’Œæ‹’ä»˜ä½£é‡‘ï¼‰")
        
        total_success_count = 0
        total_fail_count = 0
        total_saved = 0
        
        # é€å¤©åŒæ­¥
        current_date = begin_date
        while current_date <= end_date:
            logger.info("-" * 60)
            logger.info(f"æ­£åœ¨åŒæ­¥æ—¥æœŸ: {current_date.isoformat()}")
            
            day_success_count = 0
            day_fail_count = 0
            day_saved = 0
            
            for account in active_accounts:
                try:
                    logger.info(f"  åŒæ­¥è´¦å·: {account.account_name} (å¹³å°: {account.platform.platform_name if account.platform else 'æœªçŸ¥'})")
                    result = sync_service.sync_account_data(
                        account.id,
                        current_date.isoformat(),
                        current_date.isoformat()
                    )
                    
                    if result.get("success"):
                        day_success_count += 1
                        saved_count = result.get("saved_count", 0)
                        day_saved += saved_count
                        logger.info(f"    âœ“ æˆåŠŸï¼Œä¿å­˜ {saved_count} æ¡")
                    else:
                        day_fail_count += 1
                        logger.warning(f"    âœ— å¤±è´¥: {result.get('message')}")
                        
                except Exception as e:
                    day_fail_count += 1
                    logger.error(f"    âœ— å¼‚å¸¸: {e}")
            
            total_success_count += day_success_count
            total_fail_count += day_fail_count
            total_saved += day_saved
            
            logger.info(f"æ—¥æœŸ {current_date.isoformat()} å®Œæˆ: æˆåŠŸ {day_success_count}, å¤±è´¥ {day_fail_count}, ä¿å­˜ {day_saved} æ¡")
            
            current_date += timedelta(days=1)
        
        logger.info("=" * 60)
        logger.info(f"90å¤©å¹³å°ä½£é‡‘åŒæ­¥ä»»åŠ¡å®Œæˆï¼ˆå‘¨ä¸€ä¸“ç”¨ï¼‰:")
        logger.info(f"  - åŒæ­¥æ—¥æœŸæ•°: 90 å¤©")
        logger.info(f"  - æ€»æˆåŠŸæ¬¡æ•°: {total_success_count} æ¬¡")
        logger.info(f"  - æ€»å¤±è´¥æ¬¡æ•°: {total_fail_count} æ¬¡")
        logger.info(f"  - å…±ä¿å­˜: {total_saved} æ¡è®°å½•")
        logger.info(f"  - åŒ…å«: å·²ä»˜ä½£é‡‘ï¼ˆapprovedï¼‰ã€æ‹’ä»˜ä½£é‡‘ï¼ˆrejectedï¼‰ã€å¾…å®¡æ ¸ä½£é‡‘ï¼ˆpendingï¼‰")
        logger.info("=" * 60)
        
    except Exception as e:
        logger.error(f"âœ— 90å¤©å¹³å°ä½£é‡‘åŒæ­¥ä»»åŠ¡å¼‚å¸¸: {e}", exc_info=True)
    finally:
        db.close()


def sync_approved_commission_job():
    """åŒæ­¥å·²ä»˜ä½£é‡‘ä»»åŠ¡ï¼ˆæ¯æœˆ1å·å’Œ15å·åŒ—äº¬æ—¶é—´00:00æ‰§è¡Œï¼ŒåŒæ­¥æ‰€æœ‰çŠ¶æ€çš„è®¢å•ï¼Œæ›´æ–°å·²ä»˜ä½£é‡‘å­—æ®µï¼‰"""
    db: Session = SessionLocal()
    try:
        logger.info("=" * 60)
        logger.info("å¼€å§‹æ‰§è¡Œå·²ä»˜ä½£é‡‘åŒæ­¥ä»»åŠ¡...")
        
        sync_service = PlatformDataSyncService(db)
        
        # è·å–æ‰€æœ‰æ´»è·ƒçš„è”ç›Ÿè´¦å·
        active_accounts = db.query(AffiliateAccount).filter(
            AffiliateAccount.is_active == True
        ).all()
        
        logger.info(f"æ‰¾åˆ° {len(active_accounts)} ä¸ªæ´»è·ƒè´¦å·")
        
        # åŒæ­¥æœ€è¿‘90å¤©çš„æ•°æ®ï¼ˆç¡®ä¿è¦†ç›–å¯èƒ½çŠ¶æ€å˜åŒ–çš„è®¢å•ï¼‰
        end_date = date.today() - timedelta(days=1)  # æ˜¨å¤©
        begin_date = end_date - timedelta(days=89)  # 90å¤©å‰
        
        logger.info(f"æ—¶é—´èŒƒå›´: {begin_date.isoformat()} è‡³ {end_date.isoformat()} (å…±90å¤©)")
        logger.info("åŒæ­¥æ‰€æœ‰çŠ¶æ€çš„è®¢å•ï¼Œæ›´æ–°å·²ä»˜ä½£é‡‘ï¼ˆapprovedçŠ¶æ€ï¼‰")
        
        total_success_count = 0
        total_fail_count = 0
        total_saved = 0
        
        # é€å¤©åŒæ­¥
        current_date = begin_date
        while current_date <= end_date:
            logger.info("-" * 60)
            logger.info(f"æ­£åœ¨åŒæ­¥æ—¥æœŸ: {current_date.isoformat()}")
            
            day_success_count = 0
            day_fail_count = 0
            day_saved = 0
            
            # ä¸ºæ¯ä¸€å¤©åŒæ­¥æ‰€æœ‰è´¦å·
            for account in active_accounts:
                try:
                    logger.info(f"  åŒæ­¥è´¦å·: {account.account_name} (å¹³å°: {account.platform.platform_name if account.platform else 'æœªçŸ¥'})")
                    # é€å¤©åŒæ­¥ï¼Œæ¯æ¬¡åªåŒæ­¥ä¸€å¤©çš„æ•°æ®
                    result = sync_service.sync_account_data(
                        account.id,
                        current_date.isoformat(),
                        current_date.isoformat()  # å¼€å§‹å’Œç»“æŸæ—¥æœŸç›¸åŒï¼ŒåªåŒæ­¥ä¸€å¤©
                    )
                    
                    if result.get("success"):
                        day_success_count += 1
                        saved_count = result.get("saved_count", 0)
                        day_saved += saved_count
                        logger.info(f"  âœ“ è´¦å· {account.account_name} åŒæ­¥æˆåŠŸ: ä¿å­˜ {saved_count} æ¡è®°å½•")
                    else:
                        day_fail_count += 1
                        error_msg = result.get('message', 'æœªçŸ¥é”™è¯¯')
                        logger.error(f"  âœ— è´¦å· {account.account_name} åŒæ­¥å¤±è´¥: {error_msg}")
                except Exception as e:
                    day_fail_count += 1
                    logger.error(f"  âœ— è´¦å· {account.account_name} åŒæ­¥å¼‚å¸¸: {e}", exc_info=True)
            
            logger.info(f"æ—¥æœŸ {current_date.isoformat()} åŒæ­¥å®Œæˆ: æˆåŠŸ {day_success_count} ä¸ªè´¦å·, å¤±è´¥ {day_fail_count} ä¸ªè´¦å·, ä¿å­˜ {day_saved} æ¡è®°å½•")
            
            total_success_count += day_success_count
            total_fail_count += day_fail_count
            total_saved += day_saved
            
            # ç§»åŠ¨åˆ°ä¸‹ä¸€å¤©
            current_date += timedelta(days=1)
        
        logger.info("=" * 60)
        logger.info(f"å·²ä»˜ä½£é‡‘åŒæ­¥ä»»åŠ¡å®Œæˆ:")
        logger.info(f"  - åŒæ­¥æ—¥æœŸæ•°: 90 å¤©")
        logger.info(f"  - æ€»æˆåŠŸæ¬¡æ•°: {total_success_count} æ¬¡")
        logger.info(f"  - æ€»å¤±è´¥æ¬¡æ•°: {total_fail_count} æ¬¡")
        logger.info(f"  - å…±ä¿å­˜: {total_saved} æ¡è®°å½•")
        logger.info(f"  - æ›´æ–°å­—æ®µ: å·²ä»˜ä½£é‡‘ï¼ˆapprovedçŠ¶æ€çš„ä½£é‡‘ï¼‰")
        logger.info("=" * 60)
        
    except Exception as e:
        logger.error(f"å·²ä»˜ä½£é‡‘åŒæ­¥ä»»åŠ¡æ‰§è¡Œå¤±è´¥: {e}", exc_info=True)
    finally:
        db.close()



def database_backup_job():
    """æ•°æ®åº“è‡ªåŠ¨å¤‡ä»½ä»»åŠ¡ï¼ˆæ¯å¤©åŒ—äº¬æ—¶é—´ 03:00 æ‰§è¡Œï¼‰"""
    try:
        from app.services.backup_service import backup_database
        logger.info("=" * 60)
        logger.info("å¼€å§‹æ‰§è¡Œæ•°æ®åº“è‡ªåŠ¨å¤‡ä»½...")
        result = backup_database()
        if result.get("success"):
            logger.info(f"æ•°æ®åº“å¤‡ä»½å®Œæˆ: {result.get('path')} ({result.get('size_mb')} MB)")
        else:
            logger.error(f"æ•°æ®åº“å¤‡ä»½å¤±è´¥: {result.get('message')}")
        logger.info("=" * 60)
    except Exception as e:
        logger.error(f"æ•°æ®åº“å¤‡ä»½ä»»åŠ¡å¼‚å¸¸: {e}", exc_info=True)


def start_scheduler():
    """å¯åŠ¨å®šæ—¶ä»»åŠ¡è°ƒåº¦å™¨"""
    if scheduler.running:
        logger.warning("è°ƒåº¦å™¨å·²åœ¨è¿è¡Œ")
        return
    
    try:
        # 1. æ¯å¤© 04:00 - æ ¸å¿ƒåŒæ­¥ï¼šGoogle Ads æ˜¨æ—¥ + å¹³å°æ•°æ® + åˆ†æ
        scheduler.add_job(
            daily_auto_sync_and_analysis_job,
            trigger=CronTrigger(hour=4, minute=0),
            id='daily_auto_sync_and_analysis',
            name='æ¯æ—¥è‡ªåŠ¨åŒæ­¥ä¸åˆ†æï¼ˆ4:00ï¼‰',
            replace_existing=True,
            max_instances=1
        )
        
        # 2. æ¯å¤© 05:00 - å†å²æ•°æ®è‡ªåŠ¨è¡¥é½ï¼ˆé…é¢æ„ŸçŸ¥ï¼Œå…¨éƒ¨è¡¥å®Œåé›¶å¼€é”€ï¼‰
        scheduler.add_job(
            backfill_missing_data_job,
            trigger=CronTrigger(hour=5, minute=0),
            id='backfill_missing_data',
            name='å†å²æ•°æ®è‡ªåŠ¨è¡¥é½ï¼ˆ5:00ï¼‰',
            replace_existing=True,
            max_instances=1
        )
        
        # 3. æ¯å¤© 16:00 - å¹³å°æ•°æ®è¡¥å……åŒæ­¥
        scheduler.add_job(
            sync_platform_data_job,
            trigger=CronTrigger(hour=16, minute=0),
            id='sync_platform_data_afternoon',
            name='å¹³å°æ•°æ®è¡¥å……åŒæ­¥ï¼ˆ16:00ï¼‰',
            replace_existing=True,
            max_instances=1
        )
        
        # 4. æ¯æœˆ 1/15 å· 00:00 - å·²ä»˜ä½£é‡‘åŒæ­¥
        scheduler.add_job(
            sync_approved_commission_job,
            trigger=CronTrigger(day="1,15", hour=0, minute=0),
            id='sync_approved_commission',
            name='åŒæ­¥å·²ä»˜ä½£é‡‘',
            replace_existing=True,
            max_instances=1
        )
        
        # 5. æ¯å¤© 03:00 - æ•°æ®åº“è‡ªåŠ¨å¤‡ä»½ï¼ˆSEC-8ï¼‰
        scheduler.add_job(
            database_backup_job,
            trigger=CronTrigger(hour=3, minute=0),
            id='database_backup',
            name='æ•°æ®åº“è‡ªåŠ¨å¤‡ä»½ï¼ˆ3:00ï¼‰',
            replace_existing=True,
            max_instances=1
        )
        
        scheduler.start()
        logger.info("=" * 60)
        logger.info("å®šæ—¶ä»»åŠ¡è°ƒåº¦å™¨å·²å¯åŠ¨")
        logger.info("å·²æ³¨å†Œä»»åŠ¡:")
        logger.info("  1. æ¯æ—¥è‡ªåŠ¨åŒæ­¥ä¸åˆ†æ: æ¯å¤© 04:00")
        logger.info("     (Google Adsæ˜¨æ—¥ + å¹³å°æ•°æ®5å¤© + å‘¨ä¸€90å¤©ä½£é‡‘ + åˆ†æ + L7D)")
        logger.info("  2. å†å²æ•°æ®è‡ªåŠ¨è¡¥é½: æ¯å¤© 05:00")
        logger.info("     (CNYä¼˜å…ˆ, æ¯æ¬¡æœ€å¤š3MCC x 10å¤©, å…¨éƒ¨è¡¥å®Œåé›¶å¼€é”€)")
        logger.info("  3. å¹³å°æ•°æ®è¡¥å……åŒæ­¥: æ¯å¤© 16:00")
        logger.info("  4. å·²ä»˜ä½£é‡‘åŒæ­¥: æ¯æœˆ1/15å· 00:00")
        logger.info("  5. æ•°æ®åº“è‡ªåŠ¨å¤‡ä»½: æ¯å¤© 03:00")
        logger.info("=" * 60)
        
    except Exception as e:
        logger.error(f"å¯åŠ¨å®šæ—¶ä»»åŠ¡è°ƒåº¦å™¨å¤±è´¥: {e}")


def shutdown_scheduler():
    """å…³é—­å®šæ—¶ä»»åŠ¡è°ƒåº¦å™¨"""
    if scheduler.running:
        scheduler.shutdown()
        logger.info("å®šæ—¶ä»»åŠ¡è°ƒåº¦å™¨å·²å…³é—­")

